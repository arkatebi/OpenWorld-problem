#!/usr/bin/env python
'''
    This tool parses the blast result and assigns scores by implementing
    the BLAST model. It accepts the following three inputs:
           (1) a blast result file
           (2) an OBO file
           (3) an optional output file name to store the blast scores
    How to run this tool?
    Mode 1:
       > python Assign_blastScores -I1=blast_result.txt -I2=gene_ontology_edit.obo.2014-06-01
    It will create an output file blast_predictions.1
    Mode 2: 
       > python Assign_blastScores -I1=blast_result.txt -I2=gene_ontology_edit.obo.2014-06-01 -O=blast_predictions
'''
import os
import sys
from os.path import basename 
from collections import defaultdict
import math
import numpy as np

#from Bio.Blast import NCBIStandalone as ncbis

from Ontology.IO import OboIO

import configparser as cp
import shutil
import subprocess

import ArgParser_assign_blastScores as ap
import Config
import xTract_sp_trainingSet as xt
import FormatChecker as fc
import LocateDataset as ld

class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

# Default configuration file name:
config_filename = '.cafarc' 

# MAX_RSCORE is set to 500 (to be consistent with the Matlab 
# implmentation by Jiang Y):
MAX_RSCORE = 500
# Set E-value cut off by two values: E_VALUE_MAX and E_VALUE_MIN:
# E_VALUE_MAX is set 1.0 according to Jiang Y et al, ECCB 2014 Vol 30:
E_VALUE_MAX = 1.0
# E_VALUE_MIN is set by invoking sys.float_info.min system call:
E_VALUE_MIN = sys.float_info.min

class Assign_blastScores: 
    def __init__(self):
        # Collect user arguments into a dictionary:
        self.parsed_dict = ap.parse_args()

        # Collect config file entries:
        self.ConfigParam = Config.read_config(config_filename) 
        self.work_dir = self.ConfigParam['workdir']

        # Look for workspace, and if none exists create one:
        if not os.path.exists(self.work_dir):
            os.makedirs(self.work_dir) # Create work space

        #t1 = self.parsed_dict['t1'] # Extract input file name
        #print(self.parsed_dict.keys())

        self.target_fname = self.work_dir + '/' + 'testSet.9606_mfo.map'
        self.training_fname = self.work_dir + '/' + 'trainingSet.9606_mfo'
        self.GOterm_fname = self.work_dir + '/' + 'trainingSet.9606_mfo.map'

        blast_result_fname = self.parsed_dict['blast_result'] # Extract input file name
        self.blast_result_fname = ld.locate_anyfile(blast_result_fname, self.work_dir)
        obo_fname = self.parsed_dict['obo_file'] # Extract input file name
        self.obo_fname = ld.locate_anyfile(obo_fname, self.work_dir)

        # Output file name: 
        self.score_fname =  self.work_dir + '/' + 'testSet.9606_mfo.scores.txt'

        # Initialize the necessary data structures (dictionaries):
        # (1) Create query id dictionary from the query sequence map file 
              # Keys: the query sequence ids 
              # Value for each key: 1
        self.target_id_dict = {}
        self.__import_target_ids()
        # (2) Create training id dictionary from the blast result file
              # Keys: the target sequence ids
              # Value for each key: the set of training sequence ids
              #       that are retrieved from the blast results.
              # It creates a mapping such as (q, Sq).
        self.training_id_dict = defaultdict(set)
        self.__import_training_ids()
        # (3) Create a GO term dictionary from the map file between training
              # sequence ids and GO terms to store the GO terms related to
              # training sequences.
              # Keys: GO terms related to the training sequences
              # Value for each key: the training sequence ids whose functions
              #       are defined by the GO term used as the key
        self.GOterm_dict = defaultdict(set)
        self.__import_GOterms()
        # (4) Create a dictionary to store the blast results 
              # Keys: the query/target sequence ids
              # Value for each key: the set of tuples 
              # (TRseq, qseqid, sseqid, evalue, length, pident, nident) 
              # from the blast results related to the query/target sequence id 
              # used as the key
        self.blast_result_dict = defaultdict(set) 
        self.__import_blast_results()

        return None

        # Create output file names to store training sequences:
        self.trSet_LK_mfo = self.create_outfilename('LK_mfo')
        self.trSet_LK_bpo = self.create_outfilename('LK_bpo')
        self.trSet_LK_cco = self.create_outfilename('LK_cco')

        # Create output file name for mapping between SwissProt 
        self.trSet_LK_mfo_map = self.trSet_LK_mfo + '.map'
        self.trSet_LK_bpo_map = self.trSet_LK_bpo + '.map' 
        self.trSet_LK_cco_map = self.trSet_LK_cco + '.map'

    def create_outfilename(self, ontType):
        """ 
        Creates an output filename based on the output file prefix
        provided by the user and at the end returns the newly
        created output filename.
        """
        if not self.parsed_dict['outfile'] == '':
            if not basename(self.parsed_dict['g']):
                ob = basename(self.parsed_dict['outfile']) + '.tfa_' + ontType
            else:
                ob = basename(self.parsed_dict['outfile']) + '.%s.tfa_' \
                          % basename(self.parsed_dict['g']) + ontType
        else: # if output file name is NOT supplied, construct one:
            if not basename(self.parsed_dict['g']):
                ob = basename(self.parsed_dict['t1']) + '.tfa_' + ontType
            else: # if taxon id is supplied
                ob = basename(self.parsed_dict['t1']) + '.%s.tfa_' \
                          % basename(self.parsed_dict['g']) + ontType
                # output file name is constructed by appending '.taxon id.tfa'
                # as an extension
        index = 1
        while os.path.exists(self.work_dir + '/' + ob + '.' + str(index)):
            index = index + 1
        output_filename = self.work_dir + '/' + ob + '.' + str(index)
        return output_filename

    def __print_prolog(self):
        print ("*************************************************")
        print ("Running Assign_blastScore Tool!!!!!")
        print ('Following is a list of user supplied inputs:')
        for arg in self.parsed_dict:
            print (arg + ': ' + str(self.parsed_dict[arg]))
        print ('*********************************************\n')
        return None

    def __print_epilog(self):
        print(bcolors.OKGREEN + 'The following output files are created: ' +
              bcolors.ENDC)
        if os.path.exists(self.trSet_LK_mfo) and os.path.exists(self.trSet_LK_mfo_map):
            print('    MFO-Training sequence file and the corresponding map file: ')
            print('         ' + basename(self.trSet_LK_mfo))
            print('         ' + basename(self.trSet_LK_mfo_map))
        if os.path.exists(self.trSet_LK_bpo) and os.path.exists(self.trSet_LK_bpo_map):
            print('    BPO-Training sequence file and the corresponding map file: ')
            print('         ' + basename(self.trSet_LK_bpo))
            print('         ' + basename(self.trSet_LK_bpo_map))
        if os.path.exists(self.trSet_LK_cco) and os.path.exists(self.trSet_LK_cco_map):
            print('    CCO-Training sequence file and the corresponding map file: ')
            print('         ' + basename(self.trSet_LK_cco))
            print('         ' + basename(self.trSet_LK_cco_map))
        print(bcolors.OKGREEN + 'Thank you for using Training Sequence Generation Tool' + \
               bcolors.ENDC)
        return None

    def __import_target_ids(self):
        '''
        This method imports the query sequence ids from the target sequence 
        file. It saves the ids in the dictionary self.target_id_dict. 
        '''
        fh_query = open(self.target_fname, 'r')
        for line in fh_query:
            fields = line.strip().split('\t')
            self.target_id_dict[fields[0]]=1
        return None 

    def __print_target_ids(self):
        print('>', ','.join(str(t) for t in self.target_id_dict.keys()))
        return None 

    def __import_training_ids(self):
        '''
        This method imports the training sequence ids from the blast results 
        that are related to the query sequence ids:
              # Keys: query/target sequence ids
              # Value for each key: the set of training sequence ids
              #       that are retrieved from the blast results
              # it creates a mapping such as (q, Sq)
        '''
        fh_bresult = open(self.blast_result_fname, 'r')
        for line in fh_bresult:
            fields = line.strip().split('\t')
            if (fields[0] in self.target_id_dict.keys()): 
                self.training_id_dict[fields[0]].add(fields[1])

    def __print_training_ids(self):
        for k in self.training_id_dict.keys():
            print('>'+k +'\t', ','.join(str(t) for t in self.training_id_dict[k]))
        return None

    def __print_training_id(self, q):
        print('>'+q +'\t', ','.join(str(t) for t in self.training_id_dict[q]))
        return None

    def __import_GOterms(self):
        '''
        This method imports the GO terms from the map file between the 
        training ids and GO terms. It imports only those GO terms that 
        are used to define the training sequences related to the query 
        sequences. The GO terms are saved in the dictionary 
        self.GOterm_dict whose
            Keys: the GO term ids
            Value for each key: the set of training sequence ids whose
                functions are defined by the GO term used as the key.
        '''
        # Open the map file between training sequence id and GO term:
        # column 1: training sequence id
        # column 2: protein name of the training sequence
        # column 3: comma separated GO terms that define the function of
        #           the protein
        fh_trGOterms = open(self.GOterm_fname, 'r')
        for line in fh_trGOterms:
            fields = line.strip().split('\t')
            training_seq_id = fields[0]
            for gt in fields[2].split(','):
                # Checks whether the current training sequence id is 
                # in the dictionary (training_id_dict) whose keys are the 
                # training sequence ids that showed up in the blast results:
                found = False
                for qs in self.training_id_dict.keys():
                    if training_seq_id in self.training_id_dict[qs]:
                        found = True
                # If the training sequence id is in the dictionary,
                # add it to the dictionary corresponding to the GO term:
                if found:
                    self.GOterm_dict[gt].add(training_seq_id)
                #break
            #break
        fh_trGOterms.close()
        return None
    def __print_GOterms(self):
        for gt,tp in self.GOterm_dict.items():
            print(gt + '\t' + ','.join([str(e) for e in tp]))
        return None 
    def __print_GOterm(self, gt):
        print(gt + '\t' + ','.join([str(e) for e in  self.GOterm_dict[gt]]))
        return None 

    def __import_blast_results(self): 
        '''
        This method reads the blast result to extract the 
        useful information for BLAST model and populate 
        the corresponding data structure blast_result_dict:
            # Keys: the query/target sequence ids
            # Value for each key: the set of tuples
            # (TRseq, qseqid, sseqid, evalue, length, pident, nident)
            # from the blast results related to the query/target sequence id
            # denoted by the key
        ''' 
        fh_bresult = open(self.blast_result_fname, 'r') 
        for line in fh_bresult:
            fields = line.strip().split('\t')
            self.blast_result_dict[fields[0]].add(tuple(fields[1:len(fields)]))
        fh_bresult.close()
        return None 

    def __print_blast_results(self): 
        for k in self.blast_result_dict.keys():
            print('>'+k +'\n', '\n'.join(str(t) for t in self.blast_result_dict[k]))
        return None

    def __build_ontology_annotation(self, obo_fname): 
        '''
        This method builds a directed acyclic graphi (DAG) as an 
        object of OntologyGraph class from a plain-text OBO file 
        and returns the DAG object.
        '''    
        print('Inside the build_ontology_annotation() method')
        # Create an OboReader object:
        obo_parser = OboIO.OboReader(open(obo_fname))
        # Obtain an instance of OntologyGraph class by invoking 
        # read method of OboReader class:
        og = obo_parser.read()
        return og    

    def __calculate_logEvalues(self, Sv, blast_result_q): 
        '''
        q: the query sequence.
        Sv: the subset of training sequences that are experimentally
            annotated with the GO term v.
        blast_result_q: the subset of blast results between query 
           sequence q and Sv. The blast result is in the following 
           format: the set of tuples where each tuple has the following 
           format (training sequence id, qseqid, sseqid, evalue, length,
            pident, nident). See details in Blast help.
        This method calculates the log of E-values obtained from blast_result_q
        and then returns this array of E-values.
        '''
        logEvalues = np.zeros((len(blast_result_q),1))
        ind=0
        for tp in blast_result_q:
            # Pick up only the results that match with Sv
            training_seq_id = tp[0].strip()
            if training_seq_id in Sv:
                e_value = tp[1]
                # It will ignore entries whose E-value is greater than E_VALUE_MAX:
                if (float(e_value) < E_VALUE_MAX and \
                    float(e_value) <= E_VALUE_MIN):
                    # Set score to MAX_RSCORE when E-value is less
                    # than/equal to E_VALUE_MIN:
                    logEvalues[ind][0] = MAX_RSCORE
                elif (float(e_value) < E_VALUE_MAX and \
                      float(e_value) > E_VALUE_MIN):
                    # Set score to log(E-value) when E-value is greater
                    # than E_VALUE_MIN:
                    logEvalues[ind][0] = format(-1*math.log(float(e_value)), '.2f')
                ind+=1
        return logEvalues 

    def __score_targets(self):
        '''
        This method scores the target sequences based on BLAST model
        (Jiang Y et al, ECCB 2014 Vol 30).
        '''
        fh_scores = open(self.score_fname, 'w')
        fh_targets=open(self.target_fname, 'r')
        for line in fh_targets:
            q=line.strip().split('\t')[0]
            #q='T96060000001'
            #q='T96060000002'
            #q='T96060000003'
            for v in self.GOterm_dict.keys():
                #v = 'GO:0042802'
                #v = 'GO:0004725'
                Sv=self.GOterm_dict[v]
                logEvalues=self.__calculate_logEvalues(Sv, self.blast_result_dict[q])
                mScore = 0
                nScore = 0
                if len(logEvalues)>0:
                    mScore = max(logEvalues)
                    # Normalize the mScore by MAX_RSCORE:
                    nScore = round(float(mScore/MAX_RSCORE),2)
                if (float(nScore)>0.00):
                    #print("%s\t%s\t%.2f" %(q, v, nScore))
                    outstr = str(q) + '\t' + str(v) + '\t' + \
                             str("%.2f"%nScore) + '\n'
                    fh_scores.write("%s"%outstr)
                #break
            #break
        fh_scores.close() 
        fh_targets.close()
        return None

    def process_data(self):
        '''
        This method invokes other methods to perform all tasks related
        to training sequence generation.
        '''
        #q='T96060000002'
        #gt = 'GO:0004725'
        # Print the wellcome message:
        #self.__print_prolog()

        #self.__print_target_ids()
        #self.__print_training_id(q)
        #self.__print_GOterms(v)
        #self.__print_GOterm(gt)
        #self.__print_blast_results()

        # Score the target sequences 
        self.__score_targets()

        sys.exit(0)

        # Create ontogloy graph object:
        og = self.__build_ontology_annotation(self.obo_fname)
        ancestors = og.get_ancestors('GO:0000001')
        print(ancestors)

        # Print the summary of running this program:
        #self.__print_epilog()
        return None

if __name__ == '__main__':
    if len(sys.argv) == 1:
        print(sys.argv[0] + ':')
        print(__doc__)
    else:
        ab = Assign_blastScores() # Create an instance of Assign_blastScores class
        ab.process_data() # Process data and assign blast scores 
    sys.exit(0)
