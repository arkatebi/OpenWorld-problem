#!/usr/bin/env python
'''
    This tool parses the blast result and assigns scores by implementing
    the BLAST model. It accepts the following three inputs:
           (1) a blast result file
           (2) an OBO file
           (3) an optional output file name to store the blast scores
    How to run this tool?
    Mode 1:
       > python Assign_blastScores -I1=blast_result.txt -I2=gene_ontology_edit.obo.2014-06-01
    It will create an output file blast_predictions.1
    Mode 2: 
       > python Assign_blastScores -I1=blast_result.txt -I2=gene_ontology_edit.obo.2014-06-01 -O=blast_predictions
'''
import os
import sys
from os.path import basename 
from collections import defaultdict
import math

#from Bio.Blast import NCBIStandalone as ncbis

from Ontology.IO import OboIO

import configparser as cp
import shutil
import subprocess

import ArgParser_assign_blastScores as ap

import Config
import xTract_sp_trainingSet as xt
import FormatChecker as fc
import LocateDataset as ld

class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

# Default configuration file name:
config_filename = '.cafarc' 

class Assign_blastScores: 
    def __init__(self):
        # Collect user arguments into a dictionary:
        self.parsed_dict = ap.parse_args()

        # Collect config file entries:
        self.ConfigParam = Config.read_config(config_filename) 
        self.work_dir = self.ConfigParam['workdir']

        # Look for workspace, and if none exists create one:
        if not os.path.exists(self.work_dir):
            os.makedirs(self.work_dir) # Create work space

        #t1 = self.parsed_dict['t1'] # Extract input file name
        #print(self.parsed_dict.keys())

        self.target_fname = self.work_dir + '/' + 'testSet.9606_mfo.map' 
        self.training_fname = self.work_dir + '/' + 'trainingSet.9606_mfo'
        self.trGOterm_fname = self.work_dir + '/' + 'trainingSet.9606_mfo.map'

        blast_result_fname = self.parsed_dict['blast_result'] # Extract input file name
        self.blast_result_fname = ld.locate_anyfile(blast_result_fname, self.work_dir)
        obo_fname = self.parsed_dict['obo_file'] # Extract input file name
        self.obo_fname = ld.locate_anyfile(obo_fname, self.work_dir)

        return None

        # Create output file names to store training sequences:
        self.trSet_LK_mfo = self.create_outfilename('LK_mfo')
        self.trSet_LK_bpo = self.create_outfilename('LK_bpo')
        self.trSet_LK_cco = self.create_outfilename('LK_cco')

        # Create output file name for mapping between SwissProt 
        self.trSet_LK_mfo_map = self.trSet_LK_mfo + '.map'
        self.trSet_LK_bpo_map = self.trSet_LK_bpo + '.map' 
        self.trSet_LK_cco_map = self.trSet_LK_cco + '.map'

    def create_outfilename(self, ontType):
        """ 
        Creates an output filename based on the output file prefix
        provided by the user and at the end returns the newly
        created output filename.
        """
        if not self.parsed_dict['outfile'] == '':
            if not basename(self.parsed_dict['g']):
                ob = basename(self.parsed_dict['outfile']) + '.tfa_' + ontType
            else:
                ob = basename(self.parsed_dict['outfile']) + '.%s.tfa_' \
                          % basename(self.parsed_dict['g']) + ontType
        else: # if output file name is NOT supplied, construct one:
            if not basename(self.parsed_dict['g']):
                ob = basename(self.parsed_dict['t1']) + '.tfa_' + ontType
            else: # if taxon id is supplied
                ob = basename(self.parsed_dict['t1']) + '.%s.tfa_' \
                          % basename(self.parsed_dict['g']) + ontType
                # output file name is constructed by appending '.taxon id.tfa'
                # as an extension
        index = 1
        while os.path.exists(self.work_dir + '/' + ob + '.' + str(index)):
            index = index + 1
        output_filename = self.work_dir + '/' + ob + '.' + str(index)
        return output_filename

    def __print_prolog(self):
        print ("*************************************************")
        print ("Running Assign_blastScore Tool!!!!!")
        print ('Following is a list of user supplied inputs:')
        for arg in self.parsed_dict:
            print (arg + ': ' + str(self.parsed_dict[arg]))
        print ('*********************************************\n')
        return None

    def __print_epilog(self):
        print(bcolors.OKGREEN + 'The following output files are created: ' +
              bcolors.ENDC)
        if os.path.exists(self.trSet_LK_mfo) and os.path.exists(self.trSet_LK_mfo_map):
            print('    MFO-Training sequence file and the corresponding map file: ')
            print('         ' + basename(self.trSet_LK_mfo))
            print('         ' + basename(self.trSet_LK_mfo_map))
        if os.path.exists(self.trSet_LK_bpo) and os.path.exists(self.trSet_LK_bpo_map):
            print('    BPO-Training sequence file and the corresponding map file: ')
            print('         ' + basename(self.trSet_LK_bpo))
            print('         ' + basename(self.trSet_LK_bpo_map))
        if os.path.exists(self.trSet_LK_cco) and os.path.exists(self.trSet_LK_cco_map):
            print('    CCO-Training sequence file and the corresponding map file: ')
            print('         ' + basename(self.trSet_LK_cco))
            print('         ' + basename(self.trSet_LK_cco_map))
        print(bcolors.OKGREEN + 'Thank you for using Training Sequence Generation Tool' + \
               bcolors.ENDC)
        return None

    def __import_blast_result(self, blast_result_dict): 
        '''
        This method reads the blast result and extracts the 
        useful information for BLAST model. 
        ''' 
        fh_bresult = open(self.blast_result_fname, 'r') 
        for line in fh_bresult:
            fields = line.strip().split('\t')
            blast_result_dict[fields[0]].add(tuple(fields[1:len(fields)]))
        #for k in blast_result_dict.keys():
        #    print('>'+k +'\n', '\n'.join(str(t) for t in blast_result_dict[k]))
        return blast_result_dict

    def __import_trainingGOterms(self, trainingGOterm_dict):
        fh_trGOterms = open(self.trGOterm_fname, 'r')
        for line in fh_trGOterms:
            fields=line.strip().split('\t')
            for gt in fields[2].split(','):
                trainingGOterm_dict[gt].add(fields[0])
        #for gt,tp in trainingGOterm_dict.items():
        #    print(gt + '\t' + ','.join([str(e) for e in tp]))
        return trainingGOterm_dict

    def __build_ontology_annotation(self, obo_fname): 
        '''
        This method builds a directed acyclic graphi (DAG) as an 
        object of OntologyGraph class from a plain-text OBO file 
        and returns the DAG object.
        '''    
        print('Inside the build_ontology_annotation() method')
        # Create an OboReader object:
        obo_parser = OboIO.OboReader(open(obo_fname))
        # Obtain an instance of OntologyGraph class by invoking 
        # read method of OboReader class:
        og = obo_parser.read()
        return og    

    def __calculate_q2v_score(self, q, Sv, blast_result_dict): 
        '''
        q: the query sequence.
        Sv: the subset of training sequences that are experimentally
            annotated with the GO term v.
        blast_result_dict: the dictionary that contains the blast
            results. Keys are the query sequences. Values are the 
            blast results. For each query sequence, the values 
            represent blast results in the following format: the 
            set of tuples where each tuple has the following format
            (training sequence id, qseqid, sseqid, evalue, length,
            pident, nident). See details in Blast help.
        This method assigns a score to the association between a query
        sequence q and a GO term v and returns the score. The score is the
        maximum E-value from the subset of blast results between the query
        sequence and Sv.
        '''
        #print('Sv: '+str(Sv))
        score=0.00
        for tp in blast_result_dict[q]: 
            #print(tp)
            if tp[0].strip() in Sv and float(score) < float(tp[3]):
                #score = format(math.log(float(tp[3])), '.2f') 
                score = tp[3]
        return score

    def __score_targets(self, blast_result_dict, trainingGOterm_dict):
        '''
        This method scores the target sequences based on BLAST model
        ( Jiang Y et al, ECCB 2014 Vol 30).
        '''
        fh_targets=open(self.target_fname, 'r')
        for line in fh_targets:
            q=line.strip().split('\t')[0]
            #q='T96060000001'
            for v in trainingGOterm_dict.keys():
                #v = 'GO:0005080'
                Sv=trainingGOterm_dict[v]
                score=self.__calculate_q2v_score(q,Sv,blast_result_dict)
                print(q+'\t'+v+'\t'+str(score))
                #break
            #break
        return None

    def process_data(self):
        """
        This method invokes other methods to perform all tasks related
        to training sequence generation.
        """
        # Print the wellcome message:
        self.__print_prolog()
        # Import blast result:
        # Create a dictionary to store the blast results as
        # a set of tuples (TRseq, qseqid, sseqid, evalue, lenght, pident, nident) 
        blast_result_dict = defaultdict(set) 
        # Import blast resutls and save in the dictionary: 
        self.__import_blast_result(blast_result_dict)

        # Create a dictionary to store the GO terms
        # related to training sequences:  
        trainingGOterm_dict = defaultdict(set)
        self.__import_trainingGOterms(trainingGOterm_dict)

        # Score the target sequences 
        self.__score_targets(blast_result_dict, trainingGOterm_dict)

        sys.exit(0)

        # Create ontogloyg graph object:
        og = self.__build_ontology_annotation(self.obo_fname)
        ancestors = og.get_ancestors('GO:0000001')
        print(ancestors)

        # Print the summary of running this program:
        #self.__print_epilog()
        return None

if __name__ == '__main__':
    if len(sys.argv) == 1:
        print(sys.argv[0] + ':')
        print(__doc__)
    else:
        ab = Assign_blastScores() # Create an instance of Assign_blastScores class
        ab.process_data() # Process data and assign blast scores 
    sys.exit(0)
